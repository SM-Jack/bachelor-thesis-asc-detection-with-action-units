{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86472ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241bf80c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4c118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load y data\n",
    "participant_info_df = pd.read_csv(\"../Model_Input/participant_info.csv\")\n",
    "participant_info_df.sort_values('id', inplace=True) #make sure, its alphabetically sorted\n",
    "\n",
    "participants = {}\n",
    "\n",
    "participants = participant_info_df.set_index('id')['ASC'].to_dict()\n",
    "\n",
    "# rename participant ids to their corresponding dataframe name\n",
    "for k in list(participants.keys()):\n",
    "    new_key = k + \"_concat.csv\"\n",
    "    participants[new_key] = participants.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2f0ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['libreface_stats_complete.csv', 'megraph_stats_complete.csv', 'openface_stats_complete.csv'])\n"
     ]
    }
   ],
   "source": [
    "# Load X Data\n",
    "method_frames = {}\n",
    "\n",
    "for (root, dirs, file) in os.walk(\"../Model_Input/whole_video\"):\n",
    "    for f in file:\n",
    "        if \".csv\" in f:\n",
    "            path = root + \"/\" + f\n",
    "            df = pd.read_csv(path)  \n",
    "            # get rid of unknown participant\n",
    "            df = df.drop(df.loc[df['id'] == 'pre-91-020_part_1_concat.csv'].index)\n",
    "            \n",
    "            method_frames[f] = df\n",
    "\n",
    "print(method_frames.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3da04",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2437c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(data_features, labels):\n",
    "    \n",
    "    # create loocv procedure\n",
    "    cv = LeaveOneOut()\n",
    "    # create model instance\n",
    "    bst = XGBClassifier()  #(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "    # evaluate model\n",
    "    base_scores = cross_val_score(bst, data_features, labels, scoring='accuracy', cv=cv, n_jobs=-1) # 'precision', 'recall'\n",
    "    \n",
    "    return base_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228ba53",
   "metadata": {},
   "source": [
    "### Inner LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd7b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loocv(X, y):\n",
    "    classifier = XGBClassifier()\n",
    "    # Setup cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    stats = []\n",
    "    models = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the model\n",
    "        classifier.fit(X_train, y_train)\n",
    "        models.append(classifier)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # TODO check that\n",
    "        report = classification_report(y_test, predictions)\n",
    "        stats.append(report)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6af11bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(method_name):\n",
    "    df = method_frames[method_name]\n",
    "    \n",
    "    # make sure it's sorted by participant in alph. order\n",
    "    df = df.sort_values('id')\n",
    "    \n",
    "    cleaned_data = df.drop(columns=[\"id\", \"Unnamed: 0\"])\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1ddde58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If no line was printed, the data X and label y match\n"
     ]
    }
   ],
   "source": [
    "# Test if participant labels are correct with data:\n",
    "data = method_frames['openface_stats_complete.csv']\n",
    "zipped = zip(list(data[\"id\"]), list(participants.keys()))\n",
    "for l1,l2 in zipped:\n",
    "    if not l1 in l2:\n",
    "        print(f\"{l1} != {l2}\")\n",
    "print(\"If no line was printed, the data X and label y match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c41fd",
   "metadata": {},
   "source": [
    "## Replicate Openface stats as in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "882231eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_of = get_data('openface_stats_complete.csv')\n",
    "labels = np.array(list(participants.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea814767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_of.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb47877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all data: 0.640 (0.480)\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "of_loocv_scores = loocv(X_of, labels)\n",
    "print('Accuracy for all data: %.3f (%.3f)' % (np.mean(of_loocv_scores), np.std(of_loocv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9ee17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        16\n",
      "           1       0.63      0.71      0.67        17\n",
      "\n",
      "    accuracy                           0.64        33\n",
      "   macro avg       0.64      0.63      0.63        33\n",
      "weighted avg       0.64      0.64      0.63        33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.48        16\n",
      "           1       0.50      0.47      0.48        17\n",
      "\n",
      "    accuracy                           0.48        33\n",
      "   macro avg       0.49      0.49      0.48        33\n",
      "weighted avg       0.49      0.48      0.48        33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61        16\n",
      "           1       0.62      0.59      0.61        17\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.61      0.61      0.61        33\n",
      "weighted avg       0.61      0.61      0.61        33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72        17\n",
      "           1       0.71      0.62      0.67        16\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.70      0.69      0.69        33\n",
      "weighted avg       0.70      0.70      0.70        33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.52        16\n",
      "           1       0.60      0.94      0.73        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.73      0.66      0.63        32\n",
      "weighted avg       0.73      0.66      0.63        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = inner_loocv(X_of, labels)\n",
    "\n",
    "for s in stats:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece66b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed61725a",
   "metadata": {},
   "source": [
    "## LibreFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "984d69c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_lf = get_data('libreface_stats_complete.csv')\n",
    "labels = np.array(list(participants.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437d8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_lf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1910a57f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all data: 0.537 (0.499)\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "lf_loocv_scores = loocv(X_lf, labels)\n",
    "print('Accuracy for all data: %.3f (%.3f)' % (np.mean(lf_loocv_scores), np.std(lf_loocv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "965bec9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (2654832627.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[39], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    *inner_loocv(X_lf, labels)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "inner_loocv(X_lf, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15b438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce5e0805",
   "metadata": {},
   "source": [
    "## ME-Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c336ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_me = get_data('megraph_stats_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8c74f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6951219512195121\n"
     ]
    }
   ],
   "source": [
    "me_loocv_scores = loocv(X_me, labels)\n",
    "print(np.mean(me_loocv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77bb51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support\\n\\n           0       0.69      0.69      0.69        16\\n           1       0.71      0.71      0.71        17\\n\\n    accuracy                           0.70        33\\n   macro avg       0.70      0.70      0.70        33\\nweighted avg       0.70      0.70      0.70        33\\n',\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.56      0.56      0.56        16\\n           1       0.59      0.59      0.59        17\\n\\n    accuracy                           0.58        33\\n   macro avg       0.58      0.58      0.58        33\\nweighted avg       0.58      0.58      0.58        33\\n',\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.69      0.69      0.69        16\\n           1       0.71      0.71      0.71        17\\n\\n    accuracy                           0.70        33\\n   macro avg       0.70      0.70      0.70        33\\nweighted avg       0.70      0.70      0.70        33\\n',\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.83      0.59      0.69        17\\n           1       0.67      0.88      0.76        16\\n\\n    accuracy                           0.73        33\\n   macro avg       0.75      0.73      0.72        33\\nweighted avg       0.75      0.73      0.72        33\\n',\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.69      0.69      0.69        16\\n           1       0.69      0.69      0.69        16\\n\\n    accuracy                           0.69        32\\n   macro avg       0.69      0.69      0.69        32\\nweighted avg       0.69      0.69      0.69        32\\n']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_loocv(X_me, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef83cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e1e9e4d1",
   "metadata": {},
   "source": [
    "# create model instance\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "print(preds)\n",
    "print(y_test)\n",
    "print(bst.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0069b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

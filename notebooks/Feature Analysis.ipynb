{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c31a0566-8172-49e3-ac0a-8bdf1ce01e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac9316-7c14-4ce9-a143-44d2e152e422",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "41611d28-7255-49e3-9389-cfb44bcbce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frames\n",
    "data_original = {}\n",
    "\n",
    "for (root, dirs, file) in os.walk(\"../Model_Input/all_features/\"):\n",
    "    for f in file:\n",
    "        if \".csv\" in f:\n",
    "            path = root + \"/\" + f\n",
    "            df = pd.read_csv(path, index_col=[0,1,2])\n",
    "            # Remove \"Unnamed\" columns\n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            data_original[f] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7c3a2cbe-30ff-4375-b84c-3ea43af2aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['libreface_stats_parted.csv', 'me_graph_stats_parted.csv', 'openframe_stats_parted.csv', 'libreface_stats_parted-checkpoint.csv'])\n"
     ]
    }
   ],
   "source": [
    "# Parted Video data\n",
    "data_parted = {}\n",
    "\n",
    "for (root, dirs, file) in os.walk(\"../Model_Input/parted_video/\"):\n",
    "    for f in file:\n",
    "        if \".csv\" in f:\n",
    "            path = root + \"/\" + f\n",
    "            df = pd.read_csv(path)\n",
    "            df.columns.values[0] = 'part'\n",
    "            df.set_index('part', inplace=True)\n",
    "            data_parted[f] = df\n",
    "\n",
    "print(data_parted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3066cd11-ef82-474a-a096-ba15f7c5806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ASC / NT info\n",
    "participant_info_df = pd.read_csv(\"../Model_Input/participant_info.csv\")\n",
    "\n",
    "class_NT_df = participant_info_df[participant_info_df['ASC'] == 0]\n",
    "class_ASC_df = participant_info_df[participant_info_df['ASC'] == 1]\n",
    "\n",
    "NT_list = class_NT_df['id'].tolist()\n",
    "ASC_list = class_ASC_df['id'].tolist()\n",
    "\n",
    "NT_list = [f\"{s}_concat.csv\" for s in NT_list]\n",
    "ASC_list = [f\"{s}_concat.csv\" for s in ASC_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97392e-ac2e-4330-97e0-410ecb35fb8e",
   "metadata": {},
   "source": [
    "### Frames in Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c1acf4eb-904f-4a1a-bc24-e24b86bb0e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      frames  timestamps     part      speaker\n",
      "0          1        0.01  neutral      actress\n",
      "1000    1001       40.00  neutral  participant\n",
      "1650    1651       66.00      joy      actress\n",
      "2425    2426       97.00      joy  participant\n",
      "3075    3076      123.00  disgust      actress\n",
      "3900    3901      156.00  disgust  participant\n"
     ]
    }
   ],
   "source": [
    "stamp_overview = pd.read_csv(\"../Model_Input/open_face_features_timestamps.csv\", sep = ';')\n",
    "new_part_rows = stamp_overview[stamp_overview['speaker'] != stamp_overview['speaker'].shift(1)]\n",
    "print(new_part_rows)\n",
    "\n",
    "frame_stamps = {\n",
    "    \"neutral_actress\": [0, 1000],\n",
    "    \"neutral_participant\": [1001, 1650],\n",
    "    \"joy_actress\": [1651, 2425],\n",
    "    \"joy_participant\": [2426, 3075],\n",
    "    \"disgust_actress\": [3075, 3900],\n",
    "    \"disgust_participant\": [3901, 4803]\n",
    "}\n",
    "\n",
    "time_stamps = {\n",
    "    \"neutral_actress\": 40.0,\n",
    "    \"neutral_participant\": 66.00,\n",
    "    \"joy_actress\": 97.0,\n",
    "    \"joy_participant\": 123.0,\n",
    "    \"disgust_actress\": 156.0,\n",
    "    \"disgust_participant\": 192.08\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "44bde6d7-544d-4568-ba86-bb4d78807840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_AU_features(dataframe):\n",
    "    # Function to rename columns\n",
    "    def rename_columns(col):\n",
    "        match = re.match(r\"(.*_)(AU)(\\d+)(.*)?\", col)\n",
    "        if match:\n",
    "            return f\"{match.group(2)}_{int(match.group(3))}\"\n",
    "        return col\n",
    "\n",
    "    dataframe.columns = [rename_columns(col) for col in dataframe.columns]\n",
    "    return dataframe\n",
    "\n",
    "    # rename to AU_xx only\n",
    "    #mean.index = mean.index.str.replace(r'me_graph_|openface_|libreface_', '', regex=True)\n",
    "    #std.index = std.index.str.replace(r'me_graph_|openface_|libreface_', '', regex=True) # will result in i.e. \"AU2\": 0.08\n",
    "    #mean = rename_keys(mean)\n",
    "    #std = rename_keys(std)\n",
    "\n",
    "# Function to create sub-groups for each part of the video\n",
    "def create_sub_groups(df):\n",
    "    sub_groups = {}\n",
    "    previous_time = 0.0\n",
    "    for label, time in time_stamps.items():\n",
    "        sub_group = df[(df['timestamp'] >= previous_time) & (df['timestamp'] <= time)]\n",
    "        sub_groups[label] = sub_group\n",
    "        previous_time = time\n",
    "    return sub_groups\n",
    "\n",
    "# Function to create sub-groups for each part of the video\n",
    "def create_parted_dataframe(dataframes):\n",
    "    sub_groups = {}\n",
    "    previous_time = 0.0\n",
    "    for label, time in time_stamps.items():\n",
    "        participants = {}\n",
    "        for participant, df in dataframes.items():\n",
    "            sub_group = df[(df['timestamp'] >= previous_time) & (df['timestamp'] <= time)]\n",
    "            sub_group = rename_AU_features(sub_group)\n",
    "            participants[participant] = sub_group\n",
    "        sub_groups[label] = participants\n",
    "        previous_time = time\n",
    "    return sub_groups\n",
    "\n",
    "def calculate_average_over_participants(dict_part):\n",
    "    \n",
    "    \n",
    "    mean = pd.concat(dict_part).mean()\n",
    "    mean = mean.drop(labels=\"timestamp\")\n",
    "    std = pd.concat(dict_part).std()\n",
    "    std = std.drop(labels=\"timestamp\")\n",
    "    \n",
    "    return {\"mean\":mean, \"std\":std}\n",
    "\n",
    "def create_average_by_parts(dictionary):\n",
    "    # must have video-parts outside and participant-id inside\n",
    "    averages = {}\n",
    "    averages_nt = {}\n",
    "    averages_asc = {}\n",
    "    for part in dictionary.keys():\n",
    "        averages[part] = calculate_average_over_participants(dictionary[part])\n",
    "        # for NT only\n",
    "        nt_dict = {key: dictionary[part][key] for key in NT_list}\n",
    "        averages_nt[part] = calculate_average_over_participants(nt_dict)\n",
    "        # for ASC only\n",
    "        asc_dict = {key: dictionary[part][key] for key in ASC_list}\n",
    "        averages_asc[part] = calculate_average_over_participants(asc_dict)\n",
    "    return averages, averages_nt, averages_asc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "967c90b1-e852-4547-ab51-e15030a122eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame with only columns containing \"openface_\"\n",
    "data_of_binary = {}\n",
    "for key, df in data_original.items():\n",
    "    data_of_binary[key] = df.loc[:, df.columns.str.contains(r'openface_.*_c|timestamp')].copy()    \n",
    "parted_of_binary = create_parted_dataframe(data_of_binary)\n",
    "\n",
    "data_of_intensity = {}\n",
    "for key, df in data_original.items():\n",
    "    data_of_intensity[key] = df.loc[:, df.columns.str.contains(r'openface_.*_r|timestamp')].copy()\n",
    "parted_of_intensity = create_parted_dataframe(data_of_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "22659236-d621-4df1-a427-a3cf78a424c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame with only columns containing \"libreface_\"\n",
    "data_lf_binary = {}\n",
    "for key, df in data_original.items():\n",
    "    data_lf_binary[key] = df.loc[:, df.columns.str.contains(r'libreface_.*_d|timestamp')].copy()\n",
    "parted_lf_binary = create_parted_dataframe(data_lf_binary)\n",
    "\n",
    "data_lf_intensity = {}\n",
    "for key, df in data_original.items():\n",
    "    data_lf_intensity[key] = df.loc[:, df.columns.str.contains(r'libreface_.*_i|timestamp')].copy()\n",
    "parted_lf_intensity = create_parted_dataframe(data_lf_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "99c7c888-6c9f-47f8-86eb-11e56d64970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame with only columns containing \"me_graph_\"\n",
    "data_me_graph = {}\n",
    "for key, df in data_original.items():\n",
    "    data_me_graph[key] = df.loc[:, df.columns.str.contains(r'me_graph_|timestamp')].copy()\n",
    "\n",
    "parted_me = create_parted_dataframe(data_me_graph)\n",
    "# Create subgroups for every data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affd9fc-d455-4f23-9b23-850d455e0896",
   "metadata": {},
   "source": [
    "### Split by parts and Sort into ALL / NT / ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "99d52837-9b4a-40e0-8101-985e3ae0397a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "me_averages, me_averages_nt, me_averages_asc = create_average_by_parts(parted_me)\n",
    "\n",
    "lf_averages_b, lf_averages_nt_b, lf_averages_asc_b = create_average_by_parts(parted_lf_binary)\n",
    "of_averages_b, of_averages_nt_b, of_averages_asc_b = create_average_by_parts(parted_of_binary)\n",
    "\n",
    "lf_averages_i, lf_averages_nt_i, lf_averages_asc_i = create_average_by_parts(parted_lf_intensity)\n",
    "of_averages_i, of_averages_nt_i, of_averages_asc_i = create_average_by_parts(parted_of_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "11ca8901-ce47-4837-aa52-b531a6f47d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Libreface (binary)', 'Libreface (intensity)', 'Openface (binary)', 'Openface (intensity)', 'ME-Graph']\n",
    "parts = me_averages.keys()\n",
    "action_units = me_averages[\"neutral_actress\"][\"mean\"].keys()\n",
    "\n",
    "# Combine data\n",
    "all_data = {\n",
    "    'Libreface (binary)': lf_averages_b,\n",
    "    'Libreface (intensity)': lf_averages_i,\n",
    "    'Openface (binary)': of_averages_b,\n",
    "    'Openface (intensity)': of_averages_i,\n",
    "    'ME-Graph': me_averages\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92249b17-4efe-493f-b1e9-9dd53a2be97b",
   "metadata": {},
   "source": [
    "# Plotting over participant averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "35ffbb84-51f2-40f1-b4ef-849eb69d622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_AU(data, au_to_plot, filename):\n",
    "    current_methods = []\n",
    "    means = {}\n",
    "    for method in methods:\n",
    "        au_list_for_parts = []\n",
    "        for part in parts:\n",
    "            mean = data[method][part]['mean']\n",
    "            if au_to_plot in mean:\n",
    "                au_list_for_parts.append(mean[au_to_plot])\n",
    "\n",
    "        if au_list_for_parts != []:\n",
    "            means[method] = au_list_for_parts\n",
    "            current_methods.append(method)\n",
    "    \n",
    "    #method_dict = {method: [data[method][part]['mean'][au_to_plot] for part in parts] for method in methods}\n",
    "\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    for method in current_methods:\n",
    "        ax.plot(parts, means[method], marker='o', label=method)\n",
    "    \n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Parts')\n",
    "    ax.set_ylabel('Mean Values')\n",
    "    ax.set_title(f'Comparison of Methods by Parts for {au_to_plot}')\n",
    "    ax.set_xticks([p + width for p in x])\n",
    "    ax.set_xticklabels(parts)\n",
    "    ax.legend()\n",
    "    \n",
    "    # save in file\n",
    "    plt.savefig(f\"./Plots/features/{filename}{au_to_plot}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f4e44-e97c-4e6e-aa32-05e8189f7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for au in action_units:\n",
    "    plot_for_AU(all_data, au, \"Averages_\")\n",
    "    matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d14f74-5bf9-4dac-9728-3754c4392016",
   "metadata": {},
   "source": [
    "##### Plot again but separated by NT / ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "762af0d1-833f-4b4c-8bf4-6090e04daf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "nt_data = {\n",
    "    'Libreface (binary)': lf_averages_nt_b,\n",
    "    'Libreface (intensity)': lf_averages_nt_i,\n",
    "    'Openface (binary)': of_averages_nt_b,\n",
    "    'Openface (intensity)': of_averages_nt_i,\n",
    "    'ME-Graph': me_averages_nt\n",
    "}\n",
    "asc_data = {\n",
    "    'Libreface (binary)': lf_averages_asc_b,\n",
    "    'Libreface (intensity)': lf_averages_asc_i,\n",
    "    'Openface (binary)': of_averages_asc_b,\n",
    "    'Openface (intensity)': of_averages_asc_i,\n",
    "    'ME-Graph': me_averages_asc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "db931d35-0002-42bc-a356-9149d4cd7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for au in action_units:\n",
    "    plot_for_AU(nt_data, au, \"NT_averages\")\n",
    "    matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bc04ec0b-4ded-42cd-b224-5af6d159cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for au in action_units:\n",
    "    plot_for_AU(asc_data, au, \"ASC_averages\")\n",
    "    matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bed734-8416-443c-a276-0b8cd55a748f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
